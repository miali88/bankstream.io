{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import bank data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is set\n"
     ]
    }
   ],
   "source": [
    "import pandasai as pai\n",
    "import pandas as pd\n",
    "import ast\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "pai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not pai_api_key:\n",
    "    raise ValueError(\"PAI_API_KEY is not set\")\n",
    "else:\n",
    "    print(f\"OPENAI_API_KEY is set\")\n",
    "\n",
    "df = pd.read_csv(\"bank_data_23-25/barclays_072.csv\")\n",
    "\n",
    "# Sample DataFrame\n",
    "df = pai.DataFrame(df)\n",
    "\n",
    "pai.api_key.set(pai_api_key)\n",
    "\n",
    "\n",
    "### extract currency and amount\n",
    "df['currency'] = df['transactionAmount'].apply(lambda x: ast.literal_eval(x)['currency'])\n",
    "df['amount'] = df['transactionAmount'].apply(lambda x: float(ast.literal_eval(x)['amount']))\n",
    "df['amount'] = (df['amount'] * 100).astype(int)\n",
    "df = df.drop('transactionAmount', axis=1)\n",
    "\n",
    "## setting datetimeindex\n",
    "df['bookingDate'] = pd.to_datetime(df['bookingDate'])\n",
    "df.set_index('bookingDate', inplace=True)\n",
    "df = df.drop(['valueDate', 'bookingDateTime', 'valueDateTime', 'internalTransactionId'], axis=1)\n",
    "df = df.rename(columns={'remittanceInformationUnstructured': 'remittanceInfo'})\n",
    "\n",
    "# df.chat(\"What are the total expenses for 2024?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XERO TIME!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' PUT https://api.xero.com/api.xro/2.0/BankTransactions\\n    EXAMPLE BODY GET REQUEST\\n{\\n  \"BankTransactions\": [\\n    {\\n      \"Type\": \"SPEND\",\\n      \"Contact\": {\\n        \"ContactID\": \"ea791a0a-081c-4833-a4f1-3cccb323ec4a\"  \\n      },\\n      \"LineItems\": [\\n        {\\n          \"Description\": \"Foobar\",\\n          \"Quantity\": 1.0,\\n          \"UnitAmount\": 20.0,\\n          \"AccountCode\": \"433\" \\n        }\\n      ],\\n      \"BankAccount\": {\\n        \"Code\": \"600\" \\n      }\\n    }\\n  ]\\n}\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BankTransactions = { \n",
    "    \"BankTransactions\": [ { \"Type\": \"SPEND\", \n",
    "                           \"Contact\": { \"ContactID\": \"00000220-0000-0000-0000-000000000000\" }, \n",
    "                            \"Lineitems\": [ { \"Description\": \"Foobar\", \"Quantity\": 1, \"UnitAmount\": 20, \"AccountCode\": \"400\" } ], \n",
    "                            \"BankAccount\": { \"Code\": \"088\" } \n",
    "                            } ] \n",
    "}     \n",
    "\n",
    "\n",
    "\"\"\" PUT https://api.xero.com/api.xro/2.0/BankTransactions\n",
    "\n",
    "    EXAMPLE BODY GET REQUEST\n",
    "{\n",
    "  \"BankTransactions\": [\n",
    "    {\n",
    "      \"Type\": \"SPEND\",\n",
    "      \"Contact\": {\n",
    "        \"ContactID\": \"ea791a0a-081c-4833-a4f1-3cccb323ec4a\"  \n",
    "      },\n",
    "      \"LineItems\": [\n",
    "        {\n",
    "          \"Description\": \"Foobar\",\n",
    "          \"Quantity\": 1.0,\n",
    "          \"UnitAmount\": 20.0,\n",
    "          \"AccountCode\": \"433\" \n",
    "        }\n",
    "      ],\n",
    "      \"BankAccount\": {\n",
    "        \"Code\": \"600\" \n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Reconciliation Time\n",
    "\n",
    "- Add new columns \"coa_agent\", \"coa_reason\", \"coa_agent_confidence\" for LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from typing import Dict, Tuple\n",
    "import logging\n",
    "import json\n",
    "\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the ChatGroq model\n",
    "groq_model = ChatGroq(model_name=\"Llama-3.3-70b-Specdec\")\n",
    "openai_model = ChatOpenAI(model=\"gpt-4o\")\n",
    "\n",
    "\n",
    "class TransactionClassifier:\n",
    "    def __init__(self):\n",
    "        logger.info(\"Initializing TransactionClassifier\")\n",
    "        self.system_prompt = \"\"\"\n",
    "        You are a financial expert responsible for classifying transactions into appropriate chart of accounts.\n",
    "        For each transaction, you must provide:\n",
    "        1. The most specific appropriate chart of account\n",
    "        2. A brief explanation of why this classification was chosen. If confidence score is low, explain why.\n",
    "        3. A confidence score between 0 and 1 (e.g., 0.95 for high confidence)\n",
    "\n",
    "        You must respond with valid JSON in the following format only:\n",
    "        {\n",
    "            \"account\": \"string\",\n",
    "            \"reasoning\": \"string\",\n",
    "            \"confidence\": float\n",
    "        }\n",
    "        \"\"\"\n",
    "        self.last_request_time = 0\n",
    "        self.rate_limit_delay = 2  # 2 seconds between requests (30 requests/minute)\n",
    "\n",
    "    def _rate_limit(self):\n",
    "        \"\"\"Implement rate limiting\"\"\"\n",
    "        current_time = time.time()\n",
    "        time_since_last_request = current_time - self.last_request_time\n",
    "        if time_since_last_request < self.rate_limit_delay:\n",
    "            delay = self.rate_limit_delay - time_since_last_request\n",
    "            logger.debug(f\"Rate limiting: waiting {delay:.2f} seconds\")\n",
    "            time.sleep(delay)\n",
    "        self.last_request_time = time.time() \n",
    "\n",
    "    def classify_transaction(self, transaction: Dict, chart_of_accounts: list) -> Tuple[str, str, float]:\n",
    "        \"\"\"Classify a single transaction using the LLM\"\"\"\n",
    "        logger.info(f\"Processing transaction: {transaction}\")\n",
    "        self._rate_limit()\n",
    "\n",
    "        # Format the transaction details for the LLM\n",
    "        transaction_prompt = f\"\"\"\n",
    "        Please classify the following transaction:\n",
    "        Transaction: {transaction}\n",
    "        \n",
    "        \"\"\"\n",
    "\n",
    "        messages = [\n",
    "            SystemMessage(content=self.system_prompt),\n",
    "            HumanMessage(content=transaction_prompt)\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            logger.debug(\"Sending request to LLM\")\n",
    "            # Add more visible print statements\n",
    "            print(\"\\n=== Sending request to LLM ===\")\n",
    "            response = openai_model.invoke(messages)\n",
    "            print(\"\\n=== Raw LLM Response ===\")\n",
    "            print(response.content)\n",
    "            logger.debug(f\"Raw LLM response: {response.content}\")\n",
    "\n",
    "            # Try to parse the response as JSON\n",
    "            try:\n",
    "                # First, try direct JSON parsing\n",
    "                result = json.loads(response.content)\n",
    "                logger.info(\"Successfully parsed JSON response\")\n",
    "            except json.JSONDecodeError:\n",
    "                # If direct parsing fails, try to extract JSON from the response\n",
    "                logger.warning(\"Direct JSON parsing failed, attempting to extract JSON from response\")\n",
    "                # Look for JSON-like structure in the response\n",
    "                import re\n",
    "                json_match = re.search(r'\\{.*\\}', response.content, re.DOTALL)\n",
    "                if json_match:\n",
    "                    result = json.loads(json_match.group())\n",
    "                    logger.info(\"Successfully extracted and parsed JSON from response\")\n",
    "                else:\n",
    "                    raise ValueError(\"No JSON structure found in response\")\n",
    "\n",
    "            # Validate the response structure\n",
    "            required_keys = {'account', 'reasoning', 'confidence'}\n",
    "            if not all(key in result for key in required_keys):\n",
    "                missing_keys = required_keys - result.keys()\n",
    "                raise ValueError(f\"Missing required keys in response: {missing_keys}\")\n",
    "\n",
    "            logger.info(f\"Classification successful: {result['account']}\")\n",
    "            return (\n",
    "                result['account'],\n",
    "                result['reasoning'],\n",
    "                result['confidence']\n",
    "            )\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Classification failed: {str(e)}\", exc_info=True)\n",
    "            return (\n",
    "                \"ERROR\",\n",
    "                f\"Classification failed: {str(e)}\",\n",
    "                0.0\n",
    "            )\n",
    "\n",
    "\n",
    "def process_transactions(df: pd.DataFrame, chart_of_accounts: list) -> pd.DataFrame:\n",
    "    \"\"\"Process transactions in DataFrame and add classifications directly\"\"\"\n",
    "    logger.info(f\"Starting to process {len(df)} transactions\")\n",
    "    classifier = TransactionClassifier()\n",
    "\n",
    "    # Create a fresh copy of the DataFrame\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Explicitly clear any previous results\n",
    "    df['coa_agent'] = None\n",
    "    df['coa_reason'] = None\n",
    "    df['coa_confidence'] = None\n",
    "\n",
    "    for i, (idx, row) in enumerate(df.iterrows()):\n",
    "        print(\"row\", row)\n",
    "        logger.info(f\"Processing transaction {idx}\")\n",
    "        transaction = row.to_dict()\n",
    "        transaction['amount'] = transaction['amount']/100\n",
    "        account, reasoning, confidence = classifier.classify_transaction(transaction, chart_of_accounts)\n",
    "        \n",
    "        # Update DataFrame using iloc instead of at\n",
    "        df.iloc[i, df.columns.get_loc('coa_agent')] = account\n",
    "        df.iloc[i, df.columns.get_loc('coa_reason')] = reasoning\n",
    "        df.iloc[i, df.columns.get_loc('coa_confidence')] = confidence\n",
    "        \n",
    "        # Print summary of classification\n",
    "        reason_preview = ' '.join(reasoning.split()[:10]) + '...' if reasoning else 'No reason provided'\n",
    "        logger.info(f\"Transaction {idx}:\")\n",
    "        logger.info(f\"Account: {account}\")\n",
    "        logger.info(f\"Reason Preview: {reason_preview}\")\n",
    "        logger.info(\"-\" * 50)\n",
    "\n",
    "    \n",
    "    # Add verification logging\n",
    "    processed_count = df[df['coa_agent'].notna()].shape[0]\n",
    "    logger.info(f\"Number of processed transactions: {processed_count}\")\n",
    "    \n",
    "    logger.info(\"Finished processing all transactions\")\n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\" Fetch and store chart of accounts into parsed_accounts \"\"\"\n",
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open('coa.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extract only the required fields from each account\n",
    "parsed_accounts = []\n",
    "for account in data['Accounts']:\n",
    "    parsed_account = {\n",
    "        'code': account.get('AccountID', ''),\n",
    "        'name': account.get('Name', ''),\n",
    "        'status': account.get('Status', ''),\n",
    "        'type': account.get('Type', ''),\n",
    "        'taxtype': account.get('TaxType', ''),\n",
    "        'description': account.get('Description', ''),  # Note: Not present in sample but included as requested\n",
    "        'class': account.get('Class', ''),\n",
    "        'reportingcode': account.get('ReportingCode', '')\n",
    "    }\n",
    "    parsed_accounts.append(parsed_account)\n",
    "\n",
    "transactions = []  # Create empty list to store dictionaries\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    transaction = row.to_dict()\n",
    "    transactions.append(transaction)\n",
    "\n",
    "df_processed = process_transactions(df.copy(), parsed_accounts)\n",
    "\n",
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "feeding per line of transaction\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '288a56df-d4ba-4588-9ac5-613ea961d1d7',\n",
       " 'operation': 'POST /v3/transactions',\n",
       " 'status': <BatchStatus.PROCESSING: 'processing'>,\n",
       " 'created_at': datetime.datetime(2025, 2, 16, 3, 48, 3, 126241, tzinfo=TzInfo(UTC)),\n",
       " 'updated_at': datetime.datetime(2025, 2, 16, 3, 48, 3, 126241, tzinfo=TzInfo(UTC)),\n",
       " 'progress': 0,\n",
       " 'total': 1,\n",
       " 'request_id': '707ac066de354ea08d95bd4156bc4582'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ntropy_sdk import SDK\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ntropy_api_key = os.getenv(\"NTROPY_API_KEY\")\n",
    "\n",
    "sdk = SDK(ntropy_api_key)\n",
    "\n",
    "data = [{\n",
    "    \"id\": \"4yp49x3tbj9mD8DB4fM8DDY6Yxbx8YP14g565Xketw3tFmn\",\n",
    "    \"description\": \"AMAZON WEB SERVICES\",\n",
    "    \"entry_type\": \"outgoing\",\n",
    "    \"amount\": 12042.37,\n",
    "    \"currency\": \"USD\",\n",
    "    \"date\": \"2021-11-01\",\n",
    "    \"account_holder_id\": \"35b927b6-6fda-40aa-93b8-95b47c2b2cad\",  # Add this required field\n",
    "    \"location\": {\n",
    "        \"country\": \"US\"\n",
    "    }\n",
    "}]\n",
    "\n",
    "r = sdk.batches.create(\n",
    "    operation=\"POST /v3/transactions\",\n",
    "    data=data\n",
    ")\n",
    "\n",
    "\n",
    "vars(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': Entities(counterparty=Counterparty(id='2c0c799b-d003-30a6-9f53-878f3ebf46aa', name='Amazon Web Services', website='aws.amazon.com', logo='https://logos.ntropy.com/aws.amazon.com', mccs=[], type=<CounterpartyType.ORGANIZATION: 'organization'>), intermediaries=[]),\n",
       " 'categories': Categories(general='cloud computing', accounting=None),\n",
       " 'location': Location(raw_address='410 Terry Avenue North, Seattle, Washington, United States', structured=LocationStructured(street='Terry Avenue North', city='Seattle', state='Washington', postcode='98109', country_code='US', country='United States', latitude=47.622318, longitude=-122.336649, google_maps_url='https://www.google.com/maps/search/?api=1&query=47.622318,-122.336649', apple_maps_url='https://maps.apple.com/?q=47.622318,-122.336649', store_number=None, house_number='410')),\n",
       " 'error': None,\n",
       " 'created_at': datetime.datetime(2025, 2, 16, 3, 48, 3, 137880, tzinfo=TzInfo(UTC)),\n",
       " 'id': '4yp49x3tbj9mD8DB4fM8DDY6Yxbx8YP14g565Xketw3tFmn'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(vars(sdk.batches.results(id=r.id))['results'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EnrichedTransaction(entities=None, categories=None, location=None, error=TransactionError(code=<TransactionErrorCode.ACCOUNT_HOLDER_NOT_FOUND: 'account_holder_not_found'>, message='Account holder with the provided id does not exist.'), created_at=datetime.datetime(2025, 2, 16, 3, 39, 56, 176645, tzinfo=TzInfo(UTC)), id='4yp49x3tbj9mD8DB4fM8DDY6Yxbx8YP14g565Xketw3tFmn')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(sdk.batches.results(id=r.id))['results'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sdk.batches.create(\n",
    "    operation=\"POST /v3/transactions\",\n",
    "    data=transactions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': Entities(counterparty=Counterparty(id='2c0c799b-d003-30a6-9f53-878f3ebf46aa', name='Amazon Web Services', website='aws.amazon.com', logo='https://logos.ntropy.com/aws.amazon.com', mccs=[], type=<CounterpartyType.ORGANIZATION: 'organization'>), intermediaries=[]),\n",
       " 'categories': Categories(general='cloud computing', accounting=None),\n",
       " 'location': Location(raw_address='410 Terry Avenue North, Seattle, Washington, United States', structured=LocationStructured(street='Terry Avenue North', city='Seattle', state='Washington', postcode='98109', country_code='US', country='United States', latitude=47.622318, longitude=-122.336649, google_maps_url='https://www.google.com/maps/search/?api=1&query=47.622318,-122.336649', apple_maps_url='https://maps.apple.com/?q=47.622318,-122.336649', store_number=None, house_number='410')),\n",
       " 'error': None,\n",
       " 'created_at': datetime.datetime(2025, 2, 16, 1, 27, 24, 536241, tzinfo=TzInfo(UTC)),\n",
       " 'id': '4yp49x3tbj9mD8DB4fM8DDY6Yxbx8YP14g565Xketw3tFmn',\n",
       " 'request_id': '1bc4437f27404ad085a2f2f42d978015'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NTROPY_API_KEY is set\n",
      "{'details': 'Account holder with provided ID (35b927b6-6fda-40aa-93b8-95b47c2b2cad) already exists'}\n"
     ]
    }
   ],
   "source": [
    "\" NTROPY \"\n",
    "import requests\n",
    "\n",
    "ntropy_api_key = os.getenv(\"NTROPY_API_KEY\")\n",
    "if not ntropy_api_key:\n",
    "    raise ValueError(\"NTROPY_API_KEY is not set\")\n",
    "else:\n",
    "    print(f\"NTROPY_API_KEY is set\")\n",
    "\n",
    "\"\"\" CREATE NEW ACCOUNT HOLDER \"\"\"\n",
    "url = \"https://api.ntropy.com/v3/account_holders\"\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"X-API-KEY\": ntropy_api_key,\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"id\": \"35b927b6-6fda-40aa-93b8-95b47c2b2cad\",\n",
    "    \"type\": \"business\",\n",
    "    \"name\": \"Michael Ali\",\n",
    "    \"website\": \"https://flowon.ai\",\n",
    "    \"industry\": \"ai software\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '1a2bc613-111b-49b1-b35c-77e9b1d7a2fc', 'operation': 'POST /v3/transactions', 'status': 'processing', 'created_at': '2025-02-11T18:09:18.598722+00:00', 'updated_at': '2025-02-11T18:09:18.598722+00:00', 'progress': 0, 'total': 37}\n"
     ]
    }
   ],
   "source": [
    "\"\"\" NTROPY BATCH PROCESS TRANSACTIONS\"\"\"\n",
    "import uuid\n",
    "\n",
    "url = \"https://api.ntropy.com/v3/batches/\"\n",
    "\n",
    "\n",
    "data = {\n",
    "        \"operation\": \"POST /v3/transactions\",\n",
    "        \"data\": transformed_data\n",
    "    }\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "print(response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" NOW CHECK TRANSACTION STATUS \"\"\"\n",
    "batch_id = \"1a2bc613-111b-49b1-b35c-77e9b1d7a2fc\"\n",
    "\n",
    "url = f\"https://api.ntropy.com/v3/batches/{batch_id}/results\"\n",
    "\n",
    "\n",
    "get_batch = requests.get(url, headers=headers)\n",
    "\n",
    "get_batch.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'entities': {'counterparty': {'id': 'e393a472-b8bd-33e6-a889-3221b4eea280',\n",
       "   'name': 'Driver and Vehicle Licensing Agency',\n",
       "   'website': 'gov.uk.gov.uk',\n",
       "   'logo': 'https://logos.ntropy.com/business_icons-government_-_tax_-_tax_payment',\n",
       "   'type': 'organization'},\n",
       "  'intermediaries': []},\n",
       " 'categories': {'general': 'tax payment'},\n",
       " 'location': {'raw_address': 'Longview Road, Swansea SA6 7JL, United Kingdom',\n",
       "  'structured': {'street': 'Longview Road',\n",
       "   'city': 'Swansea',\n",
       "   'state': 'Swansea',\n",
       "   'postcode': 'SA6 7JL',\n",
       "   'country_code': 'GB',\n",
       "   'country': 'United Kingdom',\n",
       "   'house_number': None,\n",
       "   'latitude': 51.62079,\n",
       "   'longitude': -3.94323,\n",
       "   'google_maps_url': 'https://www.google.com/maps/search/?api=1&query=51.62079,-3.94323',\n",
       "   'apple_maps_url': 'https://maps.apple.com/?q=51.62079,-3.94323',\n",
       "   'store_number': None}},\n",
       " 'created_at': '2025-02-11T18:09:18.623135+00:00',\n",
       " 'id': '1177539c-b570-4588-9953-d76ae4647afb'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batch.json()['results'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transaction_id = \"1177539c-b570-4588-9953-d76ae4647afb\"\n",
    "\n",
    "url = f\"https://api.ntropy.com/v3/transactions/{transaction_id}\"\n",
    "\n",
    "get_transaction = requests.get(url, headers=headers)\n",
    "\n",
    "get_transaction.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "\"\"\" DF TO JSON FIELDS \"\"\"\n",
    "# Convert DataFrame to JSON\n",
    "def prepare_df_for_frontend(df):\n",
    "    # Reset index to make bookingDate a column\n",
    "    df = df.reset_index()\n",
    "    \n",
    "    # Convert datetime to ISO format string\n",
    "    df['bookingDate'] = df['bookingDate'].dt.strftime('%Y-%m-%dT%H:%M:%S')\n",
    "    \n",
    "    # Convert to JSON records format (this gives us a string)\n",
    "    json_string = df.to_json(orient='records', date_format='iso')\n",
    "    \n",
    "    # Parse the JSON string into Python objects (list of dictionaries)\n",
    "    json_data = json.loads(json_string)\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "json_data = prepare_df_for_frontend(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid \n",
    "\"\"\"  \"\"\"\n",
    "def transform_transaction(transaction, account_holder_id):\n",
    "    # Transform a single transaction\n",
    "    return {\n",
    "        \"id\": str(uuid.uuid4()),\n",
    "        \"description\": transaction[\"remittanceInfo\"],\n",
    "        \"date\": transaction[\"bookingDate\"].split(\"T\")[0],\n",
    "        \"amount\": abs(transaction[\"amount\"]/100),  # Make amount positive\n",
    "        \"entry_type\": \"outgoing\" if transaction[\"amount\"] < 0 else \"incoming\",\n",
    "        \"currency\": transaction[\"currency\"],\n",
    "        \"account_holder_id\": account_holder_id,\n",
    "        \"location\": {\n",
    "            \"country\": \"GB\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "account_holder_id = \"35b927b6-6fda-40aa-93b8-95b47c2b2cad\"\n",
    "# Transform all transactions using list comprehension\n",
    "transformed_data = [\n",
    "    transform_transaction(transaction, account_holder_id) \n",
    "    for transaction in json_data\n",
    "]\n",
    "\n",
    "transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To evaluate reponses of LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.to_csv(\"transactions_ai_reconciled.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
